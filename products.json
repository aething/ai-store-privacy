[{"id":1,"title":"AI-Driven Solutions","description":"Built on the NVIDIA Jetson Orin Nano Ecosystem","price":2845,"priceEUR":2760,"imageUrl":"https://files.stripe.com/links/MDB8YWNjdF8xTVJmb3JBaUpqSkpUWDJVfGZsX2xpdmVfRUg1V0IxdXdPUG4xWkt3Y3NxNjY1cUph00HMFzdRUP","category":"Productivity","features":["Advanced voice recognition","Smart home integration","Personalized recommendations","Cloud-based processing","Regular updates and improvements"],"specifications":["Dimensions: 4.5\" x 4.5\" x 6.3\"","Weight: 420g","Connectivity: Wi-Fi, Bluetooth 5.0","Power: AC Adapter (included)","Warranty: 1 year limited"],"hardwareInfo":"Module: Jetson Orin Nano 8GB System-on-Module (SoM)\nProcessor: 6-core ARM Cortex-A78AE v8.2 64-bit CPU, operating at 1.5 GHz (up to 1.7 GHz in MAXN mode)\nGraphics Processing Unit: NVIDIA Ampere GPU featuring 1024 CUDA cores and 32 Tensor Cores\nMemory: 8 GB 128-bit LPDDR5 with a bandwidth of 102 GB/s (a 50% increase over the previous version)\nStorage: MicroSD slot (included with the Developer Kit) or NVMe SSD via M.2 Key M (optional)\nInterfaces: 4x USB 3.2 Gen 2 ports, 2x CSI camera connectors, DisplayPort 1.4, Gigabit Ethernet, and an M.2 Key E slot\nCooling: Pre-installed thermal solution (heatsink) with an active fan\nPower: Configurable power consumption ranging from 7 to 25 watts, adjustable via power modes","softwareInfo":"The AI-driven chatbot solution deployed on this hardware platform utilizes a highly efficient, open-source language model optimized for edge computing, alongside a suite of supporting software components.\n\nLanguage Model:\n• Parameter Size: Approximately 2–7 billion parameters, ensuring a balance between performance and resource efficiency.\n• Precision: Supports 4-bit quantization (e.g., INT8 or GGUF format) to fit within the 8 GB RAM constraint while maintaining quality.\n• Context Window: Configurable up to 4096–8192 tokens (~3000–6000 words, equivalent to 10–20 pages of A4 text), enabling robust handling of enterprise knowledge bases.\n• Performance: Capable of generating 5–10 tokens per second during inference, suitable for sequential processing of user queries.\n• Licensing: Fully open-source with permissive licensing (e.g., MIT or Apache 2.0), allowing unrestricted use, modification, and deployment within organizational networks.\n\nAdditional Software Components:\n• Inference Engine: A lightweight runtime environment optimized for GPU acceleration, leveraging CUDA and tensor core capabilities to maximize inference speed on the hardware.\n• Text Processing Framework: A modular toolkit for tokenization, embedding generation, and text preprocessing, enabling seamless integration of enterprise-specific datasets into the model's knowledge base.\n• Knowledge Base Integration: A retrieval-augmented generation (RAG) system that indexes and retrieves relevant textual data from an external storage medium (e.g., microSD or NVMe), supporting up to 500 GB of unstructured text data (approximately 200 million A4 pages).\n• Networking Layer: A secure, local server framework (e.g., RESTful API) for handling user queries within the enterprise intranet, ensuring data privacy and low-latency responses.\n• Installation Requirements: Compatible with a Linux-based operating system, requiring approximately 20–50 GB of storage for the OS, model weights, and supporting libraries.","stripeProductId":"prod_S2weDSF2MH6Hl7","currency":"usd"},{"id":2,"title":"Machine Learning Systems","description":"ML Systems Leveraging the NVIDIA DGX Spark","price":6445,"priceEUR":6395,"imageUrl":"https://files.stripe.com/links/MDB8YWNjdF8xTVJmb3JBaUpqSkpUWDJVfGZsX2xpdmVfOHVIeTVCNjRNOVdoQTV3MU4wY2JZV3BP00D9UT9nSf","category":"Smart Home","features":["Multi-room audio","Compatible with major smart home ecosystems","Energy usage monitoring","Voice-controlled shopping","Multi-user recognition"],"specifications":["Dimensions: 5.7\" x 5.7\" x 4.2\"","Weight: 580g","Connectivity: Wi-Fi, Bluetooth 5.0, Zigbee","Power: AC Adapter (included)","Warranty: 2 years limited"],"hardwareInfo":"The Machine Learning Systems (ML Systems) leveraging the NVIDIA DGX Spark utilize a high-performance, compact supercomputing platform tailored for advanced AI workloads. The kit is based on the NVIDIA DGX Spark (previously Project Digits), featuring the GB10 Grace Blackwell Superchip. This includes a 20-core ARMv9 CPU (10 Cortex-X925 + 10 Cortex-A725) and a Blackwell GPU with 5th-generation Tensor Cores and 4th-generation RT Cores, delivering up to 1 petaflop (1000 TOPS) in FP4 precision. It is equipped with 128 GB of unified LPDDR5x memory (273 GB/s bandwidth) and 1 TB NVMe SSD storage in the base configuration (expandable to 4 TB). Connectivity includes 4x USB4 (Type-C, 40 Gbit/s), HDMI 2.1a, 10GbE Ethernet, Wi-Fi 7, Bluetooth 5.3, and a ConnectX-7 (200 Gbit/s RDMA) interface for clustering. Power consumption is approximately 170 watts, supplied via USB-C, and the system operates on NVIDIA DGX OS (Ubuntu-based) with a pre-installed NVIDIA AI stack (PyTorch, NeMo, RAPIDS). This hardware provides a robust foundation for deploying a dual-purpose chatbot and voice assistant system within enterprise or organizational settings.","softwareInfo":"The ML system deployed on this platform employs an advanced, open-source machine learning model optimized for natural language processing and multimodal capabilities, supported by a comprehensive software ecosystem. Below is a depersonalized specification reflecting the system's capabilities without identifying specific vendors or developers:\n\nMachine Learning Model:\n• Parameter Size: Approximately 7–13 billion parameters, balancing computational efficiency with high-quality language understanding and generation.\n• Precision: Supports mixed precision (e.g., FP16 or 4-bit quantization such as INT8/GGUF), enabling operation within 128 GB memory while maximizing throughput.\n• Context Window: Configurable up to 8192–32,768 tokens (~6000–24,000 words, equivalent to 20–80 A4 pages), facilitating extensive contextual analysis for complex queries leveraging a robust knowledge base.\n• Performance: Capable of generating 20–50 tokens per second during inference, supporting real-time text and voice interactions with minimal latency.\n• Multimodal Capabilities: Integrates speech-to-text (STT) and text-to-speech (TTS) functionalities, processing audio inputs in real-time (0.5–1 second latency) and synthesizing natural-sounding speech outputs (<200 ms latency).\n• Licensing: Fully open-source with permissive licensing (e.g., MIT or Apache 2.0), permitting unrestricted use, modification, and commercial deployment.\n\nAdditional Software Components:\n• Inference Engine: A high-performance runtime optimized for GPU acceleration, utilizing advanced tensor computation and parallel processing to enhance inference speed and efficiency.\n• Speech Processing Framework: A modular system for real-time audio capture, speech recognition, and voice synthesis, supporting multiple languages and customizable voice profiles.\n• Knowledge Base Integration: A retrieval-augmented generation (RAG) system capable of indexing and querying up to 1 TB of unstructured data (approximately 400 million A4 pages), enabling dynamic access to enterprise knowledge repositories.\n• Networking Layer: A secure, intranet-compatible server framework (e.g., RESTful or WebSocket API) for handling simultaneous text and voice queries, ensuring data privacy and scalability within organizational networks.\n• Installation Requirements: Compatible with a Linux-based operating system, requiring approximately 50–100 GB of storage for the OS, model weights, speech modules, and supporting libraries.","stripeProductId":"prod_S2whEs3ic8h33z","currency":"usd"},{"id":3,"title":"Intelligent Automation Systems  ","description":"AI-Driven Platform based on NVIDIA’s Founders Edition","price":8630,"priceEUR":8430,"imageUrl":"https://files.stripe.com/links/MDB8YWNjdF8xTVJmb3JBaUpqSkpUWDJVfGZsX2xpdmVfZW5sd3pKRmdxVlcxcHVwZldLT3VhZWNu00hcPi5wOn","category":"Education","features":["Personalized learning paths","Progress tracking","Interactive lessons","Parent/teacher dashboard","Offline content access"],"specifications":["Dimensions: 9.5\" x 6.3\" x 0.4\"","Weight: 350g","Connectivity: Wi-Fi, Bluetooth 4.2","Battery: Up to 12 hours","Warranty: 1 year limited"],"hardwareInfo":"The Intelligent Automation Systems platform is built on NVIDIA's Founders Edition hardware, featuring the NVIDIA RTX™ 6000 Ada Generation GPU. This high-performance computing system is powered by an Ada Lovelace architecture with 18,176 CUDA® cores, 568 4th-generation Tensor Cores, and 142 3rd-generation RT cores. It provides 142 TFLOPS of FP32 performance and 568 TFLOPS of Tensor performance in FP16, enabling advanced AI-driven automation capabilities. The system is equipped with 48 GB of GDDR6 memory with ECC support, delivering a bandwidth of 864 GB/s, complemented by a 256-bit memory interface. For storage, it includes a 2 TB NVMe SSD with read speeds up to 7,000 MB/s. Connectivity options include 4× DisplayPort 1.4 outputs, PCIe 4.0 ×16 interface, USB 3.2 Type-C with DisplayPort 1.4a Alt Mode, and 10 Gigabit Ethernet. The system operates with a thermal design power (TDP) of 300W, managed by an advanced active cooling solution, and measures 267mm × 112mm × 52mm. This hardware foundation provides exceptional computational resources for enterprise automation tasks, robotic process automation (RPA), and voice assistance functionality.","softwareInfo":"The AI-driven platform employs an advanced, open-source machine learning model and a suite of supporting software tailored for intelligent automation, text-based interactions, and voice assistance. Below is a depersonalized specification reflecting the system's capabilities without identifying specific vendors or developers:\n\nMachine Learning Model:\n• Parameter Size: Approximately 13–20 billion parameters, providing robust performance for automation, natural language understanding, and generation tasks.\n• Precision: Supports mixed precision (e.g., FP16 or 4-bit quantization like INT8), optimizing memory usage within the 24 GB GDDR6X constraint while maintaining high throughput.\n• Context Window: Configurable up to 16,384–65,536 tokens (~12,000–48,000 words, equivalent to 40–160 A4 pages), enabling deep contextual analysis for automation workflows and multi-turn dialogues.\n• Performance: Capable of generating 30–60 tokens per second during inference, supporting real-time text and voice interactions with low latency.\n• Multimodal Capabilities: Integrates speech-to-text (STT) and text-to-speech (TTS) with processing latencies of 0.3–0.8 seconds for STT and <150 ms for TTS, facilitating seamless voice-driven automation.\n• Licensing: Fully open-source with permissive licensing (e.g., MIT or Apache 2.0), allowing unrestricted enterprise customization and deployment.\n\nAdditional Software Components:\n• Inference Engine: A GPU-accelerated runtime leveraging CUDA and Tensor Cores for high-speed inference, optimized for the Ada Lovelace architecture to maximize automation and chatbot performance.\n• Automation Framework: A modular system for designing, executing, and monitoring workflows, capable of integrating with enterprise APIs, robotic process automation (RPA), and IoT devices for end-to-end process automation.\n• Speech Processing Framework: A real-time audio processing suite for STT and TTS, supporting multilingual inputs and customizable voice outputs for voice assistant functionality.\n• Knowledge Base Integration: A retrieval-augmented generation (RAG) system indexing up to 2 TB of unstructured data (~800 million A4 pages), enabling dynamic access to enterprise repositories for automation and query resolution.\n• Networking Layer: A secure, local server framework (e.g., RESTful or WebSocket API) for handling text, voice, and automation requests within an enterprise intranet, ensuring privacy and scalability.\n• Installation Requirements: Compatible with a Linux-based OS (e.g., Ubuntu), requiring ~50–100 GB of storage for the OS, model weights, automation scripts, and libraries.","stripeProductId":"prod_S2wtA0M11BUBKs","currency":"usd"},{"id":4,"title":"AI Healthcare Analytics","description":"Advanced monitoring systems with built-in NVIDIA accelerated computing for real-time health analytics and predictive diagnostics.","price":2499900,"priceEUR":2299900,"imageUrl":"https://images.unsplash.com/photo-1686191669169-b42fcd632af0?auto=format&fit=crop&w=600&h=400","category":"Health & Fitness","features":["24/7 heart rate monitoring","Sleep quality analysis","Stress level tracking","Exercise recognition","Personalized health insights"],"specifications":["Dimensions: 44mm x 38mm x 10.7mm","Weight: 48g","Connectivity: Bluetooth 5.1, NFC","Battery: Up to 7 days","Water resistance: 5 ATM"],"hardwareInfo":"Процессор: Dual-core ARM Cortex-M33 @ 96MHz\nПамять: 512KB RAM\nХранение: 32MB Flash\nЭкран: 1.4\" AMOLED, 454x454, 326 PPI, всегда активный\nСенсоры: Оптический пульсометр, Акселерометр, Гироскоп, Альтиметр, Термометр, ЭКГ, Пульсоксиметр\nБатарея: 420mAh, до 7 дней автономной работы\nЗарядка: Беспроводная (Qi), полная зарядка за 1.5 часа\nВодонепроницаемость: 5 ATM (до 50 метров)\nМатериалы: Титановый корпус, Сапфировое стекло, Гипоаллергенный силиконовый ремешок","softwareInfo":"Операционная система: AethingOS Health Edition 1.5\nПоддерживаемые языки: Русский, English, Deutsch, Français, Español, Italiano, 日本語, 中文\nОтслеживание активности: 30+ видов спорта с продвинутыми метриками\nМониторинг здоровья: Пульс, ЭКГ, Кислород в крови, Температура тела, Качество сна, Уровень стресса\nОповещения: Уведомления со смартфона, звонки, сообщения, календарь\nПерсонализация: 200+ циферблатов, настраиваемые сложные функции\nСинхронизация: Автоматическая с Aether Health Cloud, экспорт в Apple Health и Google Fit\nАналитика: AI-анализ данных здоровья с персональными рекомендациями","stripeProductId":null,"currency":"usd"}]