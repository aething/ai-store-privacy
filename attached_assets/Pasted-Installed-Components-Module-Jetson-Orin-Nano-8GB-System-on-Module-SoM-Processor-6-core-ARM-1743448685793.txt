Installed Components

Module: Jetson Orin Nano 8GB System-on-Module (SoM). 
Processor: 6-core ARM Cortex-A78AE v8.2 64-bit CPU, operating at 1.5 GHz (up to 1.7 GHz in MAXN mode). 
Graphics Processing Unit: NVIDIA Ampere GPU featuring 1024 CUDA cores and 32 Tensor Cores. 
Memory: 8 GB 128-bit LPDDR5 with a bandwidth of 102 GB/s (a 50% increase over the previous version). 
Storage: MicroSD slot (included with the Developer Kit) or NVMe SSD via M.2 Key M (optional). 
Interfaces: 4x USB 3.2 Gen 2 ports, 2x CSI camera connectors, DisplayPort 1.4, Gigabit Ethernet, and an M.2 Key E slot with a pre-installed Wi-Fi module. 
Cooling: Pre-installed thermal solution (heatsink) with an active fan. 
Power: Configurable power consumption ranging from 7 to 25 watts, adjustable via power modes.
AI Capabilities and Performance Characteristics (Per NVIDIA)
AI Performance: Up to 67 TOPS (INT8), representing a 70% improvement over the prior version (40 TOPS), achieved through the software update (JetPack 6.1, December 2024). 
Generative AI: Support for modern generative AI models, including transformer-based architectures (e.g., Vision Transformers and Large Language Models up to 8B parameters, such as Llama-3.1-8B), with accelerated inference on the Ampere architecture. 
Energy Efficiency: Optimized for edge devices with a power draw of 7–25 watts, establishing it as a leader in energy-efficient AI computing. 
Software Stack: Full compatibility with NVIDIA JetPack SDK (v6.1), encompassing CUDA, TensorRT, cuDNN, and frameworks such as Hugging Face Transformers, Ollama, and NVIDIA Isaac ROS for robotics applications. 
Applications: Enables development of solutions for robotics, computer vision, multimodal agents, and IoT at the network edge. Ideal for prototyping and rapid product deployment, supported by NVIDIA’s cloud workflows. 
Features: Capable of locally executing large language models (LLMs), enhancing privacy, and reducing latency compared to cloud-based solutions.
